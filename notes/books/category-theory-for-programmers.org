* Category Theory for Programmers
** Chapters
*** Category

A category consists of objects and arrows (morphisms). Arrows can be
composed, and the composition is associative. Every object has an
identity arrow that serves as a unit under composition.

*** Bottom as a representation of non-terminating computation

We can't just ban non-terminating functions because distinguishing between
terminating and non-terminating functions is undecidable - the famous halting
problem.

That's why computer scientists came up with an idea, to extend every type
by one more special value called the bottom (denoted by _|_ in Haskell).

This *value* corresponds to a non-terminating computation. In practice, when
proving correctness of the program, it is easier to drop out Bottom and
treat all functions as always terminating.

*** Denotational Semantics

Testing is a poor substitution of proof.

Consider following Haskell program, which calculates factorial:

fact n = product [1..n]

It has straightforward definition, which is nice and clean, almost equal
with the math book. In denotational semantics every programing construct
is given its mathematical interpretation. With that, if you want to prove
a property of a program, you just prove a mathematical theorem.

However considering more pragmatic and actual problems (which are more
related with programming than with math) usage of *denotational semantics*
is much more harder.

The breakthrough came from category theory. Eugenio Moggi discovered that
any computational effect can be mapped to monads.

*** Monoid

A monoid is defined as a set with a binary operation. All that’s required
from this operation is that it’s associative, and that there is one special
element that behaves like a unit with respect to it.

In Haskell we would define a Monoid like this:

class Monoid m where
  mempty  :: m
  mappend :: m -> m -> m

You have to make sure that two properties are enforced - a neutrality of
`mempty` element and that `mappend` is associative. Commutativity is not
part of the definition so thanks to that a `String` or `Array` can be a
Monoid.

*** Kleisli Categories

Kleisli category has, as objects, the types of the underlying programming
language. Morphisms from type A to type B are functions that go from A to
a type derived from B using the particular embellishment. Each Kleisli
category defines its own way of composing such morphisms, as well as the
identity morphisms with respect to that composition.

*** Products and Coproducts

Every object is defined by its relationships - with itself and with
the other objects. These relationships are defined by morphisms.

The initial object is the object that has one and only one morphism
going to any object in the category. It guarantees the next best
thing: uniqueness up to isomorphism.

Example: The initial object in a partially ordered set (often
called a poset) is its least element. Some posets don’t have an
initial object — like the set of all integers, positive and negative.

The terminal object is the object with one and only one morphism
coming to it from any object in the category.

The terminal object is unique, up to isomorphism. In the category
of sets, the terminal object is a singleton.

You can’t help but to notice the symmetry between the way we defined
the initial object and the terminal object. The only difference
between the two was the direction of morphisms. It turns out that for
any category C we can define the opposite category C^op just by
reversing all the arrows. The opposite category automatically
satisfies all the requirements of a category, as long as we
simultaneously redefine composition.

It follows then that a terminal object is the initial object in
the opposite category.

**** Isomorphism

The intuition is that isomorphic objects look the same — they have
the same shape. An isomorphism is an invertible morphism, or a pair
of morphisms, one being the inverse of the other.

Morphism g is the inverse of morphism f if their composition is
the identity morphism:

f . g = id
g . f = id

**** Products and Coproducts - Definitions

Let's define a product of two objects in any category using the
same universal construction. Such product doesn’t always exist,
but when it does, it is unique up to a unique isomorphism.

A product of two objects a and b is the object c equipped with
two projections such that for any other object c’ equipped with
two projections there is a unique morphism m from c’ to c
that factorizes those projections.

A coproduct of two objects a and b is the object c equipped
with two injections such that for any other object c’ equipped
with two injections there is a unique morphism m from c to c’
that factorizes those injections.

In the category of sets, the coproduct is the disjoint union of
two sets. An element of the disjoint union of a and b is
either an element of a or an element of b.

The canonical implementation of the coproduct is a data type
called Either, which is defined in the standard Prelude as:

Either a b = Left a | Right b

A product behaves like multiplication, with the terminal object
playing the role of one; whereas coproduct behaves more like
the sum, with the initial object playing the role of zero. In
particular, for finite sets, the size of the product is the
product of the sizes of individual sets, and the size of the
coproduct is the sum of the sizes.

*** Simple Algebraic Data Types

A lot of mechanisms can be built with use of basic types - products
and coproducts.  This fact has important practical consequences. Many
properties of data structures are composable - if you know how to
compare values of basic types for equality, and you know how to
generalize these comparisons to product / coproduct types you can
automate the derivation of equality operators for composite types.

We have sum types with 'Void' as the neutral element, and the product
types with the unit type, '()' as the neutral element. We'd like to
think of them as analogous to addition and multiplation. Using them
separately can be used to define a variety of useful data structures,
but the real power comes from combining the two.

Mathematicians have a name for two intertwined monoids: it’s called a
semiring.  It’s not a full ring, because we can’t define subtraction
of types.

Sample translation table with some entries of interest:

| Numbers   | Types                             |
|-----------+-----------------------------------|
| 0         | Void                              |
| 1         | ()                                |
| a + b     | Either a b = Left a \vert Right b |
| a * b     | (a, b) or Pair a b = Pair a b     |
| 2 = 1 + 1 | data Bool = True \vert False      |
| 1 + a     | data Maybe = Nothing \vert Just a |

Logical and and or also form a semiring, and it too can be mapped into
type theory:

| Logic          | Types                             |
|----------------+-----------------------------------|
| false          | Void                              |
| true           | ()                                |
| a \vert\vert b | Either a b = Left a \vert Right b |
| a && b         | (a, b)                            |

*** Functors

Functor is a mapping between categories. Given two categories, C and
D, a functor F maps objects in C to objects in D. But a category it is
not just objects - it's objects and morphisms that connect them. A
functor also maps morphisms - it's a function on morphisms. It
preserves connections.

There is also composition of morphisms. If h is a composition of f and
g:

h = f . g

We want its image under F to be a composition of the images of f and
g:

F h = F g . F f

Functors that map this category into itself are called
*endofunctors*. Haskell's Maybe type it's only a type constructor, but
we can turn it into a functor.

*** Functoriality

As with the functions, you can have functors with multiple arguments -
they are called *bifunctors*, it maps every pair of objects, one from
category C and one from category D to an object in category E. Notice,
that this is a mapping from a *cartesian product* of categories CxD to
E.

In such case functoriality means that bifunctors has to map morphisms
as well. Pair of morphisms is a single morphism in the product
category CxD.

(f, g) . (f', g') = (f . f', g . g')

Composition is associative and it has an identity, so it is a category
as well.

*** Function Types

Function type *a->b* is more than simple type: it's a set of morphisms
between objects *a* and *b*. A set of morphisms between two objects in
any category is called a *hom-set*. It just so happens that in the
category *Set* every *hom-set* is itself an object in the same
category - because it is, after all, a set.

It's the self-referential nature of the category *Set* that makes
function types special. But there is a way, at least in some
categories, to construct objects that represent *hom-sets*. Such objects
are called *internal hom-sets*.

Function application (or evaluation) connects three types (argument
type, function type and result type) in a set.

A function object from *a* to *b* is an object *a->b* together with
the morphism *eval :: ((a->b) x a) -> b* such that for any other
object *z* with a morphism:

  *g :: z x a -> b*

There is a unique morphism.

  *h :: z -> (a->b)*

That factors g through eval:

  *g = eval . (h x id)*

*** Natural Transformations

We talked about functors as mappings between categories that preserve
their structure. A functor *embeds* one category in another. It may
collapse multiple things into one, but it never breaks
connections. One way of thinking about it is that with a functor we
are modeling one category inside another. The source category serves
as a model, a blueprint, for some structure that’s part of the target
category.

A natural transformation is a selection of morphisms: for every object
`a`, it picks one morphism from `F a` to `G a`. If we call the natural
transformation `alfa`, this morphism is called the component of `alfa`
at `a`, or `alfa_a`.

  `alfa_a :: F a -> G a`

In Haskell, a polymorphic function must be defined uniformly for all
types. One formula must work across all types. This is called
*parametric polymorphism*.

Functors may be looked upon as objects in the functor category. As
such, they become sources and targets of morphisms: *natural
transformations*. A natural transformation is a special type of
polymorphic function.

*** Category Theory and Declarative Programming

Difference between declarative and imperative composition. First looks
like this:

`h = g . f`

Second:

`h x = let y = f x in g y`

Imperative version is a sequence of actions, declarative how to
compose things, and language / compiler etc. can execute them lazily.

In other words you can say that declarative programming can be
deferred in time, any optimization related with time or laziness can
be applied to it. It is harder to do it in imperative programming,
because of way how the parts are composed / combined.

And as it comes with physical duality, category theory encourages a
global approach and therefore supports declarative programming.

*** Limits and Colimits
*** Free Monoids
*** Representable Functors
*** The Yoneda Lemma
*** Yoneda Embedding
*** It’s All About Morphisms
*** Adjunctions
