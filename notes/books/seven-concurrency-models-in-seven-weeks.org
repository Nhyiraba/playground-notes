* Seven Concurrency Models in Seven Weeks
** Threads and Locks (Java)
*** Threads and Intrinsic Locks - Lock, Mutex, Critical Section
*** Beyond Shared State and Basic Abstractions - Memory Model (JSR 133)
*** Atomic Variables, Thread Pools
** Functional Programming (Clojure)
*** Immutability and Functional Approach
*** Reducers and Functional Concurrency
*** Functional Parallelism
** Separating identity from State (Clojure)
*** Atoms
**** Impure != Imperative
**** Structure sharing is possible thanks to immutability
*** Agents and Refs
**** Agent != Actor
**** References - coordination, Agents & Atoms - isolation
**** Retries favors side-effect free functions
*** STM (Software Transactional Memory)
**** Transactions are not bad, support for "ACI" without "D"
**** Retries favors side-effect free functions
** Actors (Elixir)
*** Actors - Basics
**** Mailboxes and PIDs.
**** Asynchronous nature by default.
**** Able to create synchronous nature easily.
**** Groups are multi-threaded, single is single-threaded and linear.
**** Encourages immutability (recursion) and encapsulation.
**** More object-oriented than objects (true nature of OOP - words of Alan Kay).
*** Fault Tolerance
**** "Let it crash" philosophy.
**** Supervisors, Links and Monitors.
**** Error kernel concept.
*** Distribution and OTP
**** Actor model needs and eases standardization.
**** Behaviors are the key.
**** OTP means just OTP (like IBM means IBM only now).
**** Referential transparency.
** Communicating Sequential Processes (Clojure)
*** Channels, Go and Macros
**** Un-buffered channels are the default.
**** When buffered, need to provide a size (every queue has the size).
**** Macros are solving other macros issues (`!!>` vs. `!>` and using second outside of `go`).
*** Collections, Transducers and Patterns
*** Roots and Design Rationale
**** Tony Hoare - Creator, Author and Inventor.
**** core.async - Rich Hickey's word: "Actor binds producer and consumer, and it contains queue inside. So queues are much more primitive asset."
** Data Parallelism (OpenCL, C)
*** Pipelineing and Multiplication
**** Different approach to the same thing.
**** Current GPUs are using mixed approach (both at the same time).
**** Kernel is the key piece of that puzzle.
**** C / C++ are the official bindings to *OpenCL*, but it is possible to host it in different languages as well (presented in book regarding *Java*).
*** Synchronization and Splitting the workload
**** Thinking in terms of single instruction that multiplies the workload.
**** Data layout is often the most important thing.
**** Work groups, work items and synchronization (*barriers*, *lock-free algorithms*) are also the keys.
*** Integration
**** It is easy to connect OpenCL with OpenGL.
**** You can integrate that framework with a lot of languages, kernels can be written in different language and then they'll use OpenCL underneath.
** The Lambda Architecture (Java, Clojure)
*** Thinking in terms of data and tools.
**** Hadoop and Storm (older alternative to Spark).
**** Big Data is one thing, for long running computation the more important thing is fault tolerance.
**** Data are immutable! No delete, no edits, that's why you can retry and split the workload.
**** How big is big? Dozens of terabytes and more.
*** Batch layer.
**** Thinking about data in form of a raw, complete storage and batch layer like a derived layer, which you can always calculate from it.
**** Redoing calculations and retrying them when they failed is more important, especially if you'll treat it as the daily process.
**** Frameworks have already a lot of data formats supported (obvious are *XML*, *JSON*, *Open Data* etc.).
*** Speed layer.
**** Streaming is the future (*Spark*, *Storm*).
**** It is often a workaround and answer for deficiencies of batch layer.
**** But it can't replace everything - batching is still needed, but it can be replaced by streaming computation.
**** Declarative way of defining a pipeline, then optimization layer does the hard work.
**** Important especially for expiring data.
